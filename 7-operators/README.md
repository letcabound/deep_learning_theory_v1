# 1 Convolution
## 1.1 Conv2D
- ç¤ºæ„å›¾<br>
![figure](images/op-figure1.jpg)

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)
```python
import torch
import torch.nn as nn
# With square kernels and equal stride
m = nn.Conv2d(16, 33, 3, stride=2)
# non-square kernels and unequal stride and with padding
m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))
# non-square kernels and unequal stride and with padding and dilation
m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))
input = torch.randn(20, 16, 50, 100)
output = m(input)
```

## 1.2 ConvTranspose2d
- å›¾ç¤º <br>
![figure2](images/op-figure2.jpg)

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d)

```python
import torch
import torch.nn as nn
# With square kernels and equal stride
m = nn.ConvTranspose2d(16, 33, 3, stride=2)
# non-square kernels and unequal stride and with padding
m = nn.ConvTranspose2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))
input = torch.randn(20, 16, 50, 100)
output = m(input)
# exact output size can be also specified as an argument
input = torch.randn(1, 16, 12, 12)
downsample = nn.Conv2d(16, 16, 3, stride=2, padding=1)
upsample = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1)
h = downsample(input)
h.size()

output = upsample(h, output_size=input.size())
output.size()
```

# 2 çº¿æ€§å˜æ¢å±‚
## 2.1 Linear/Gemm
**å›¾ç¤º** <br>
![figure9](images/op-figure9.jpg)

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)
```python
import torch
import torch.nn as nn
m = nn.Linear(20, 30) # A[m,k]*W[k,n] = O[m,n] --> 20 = k, 30 = n
input = torch.randn(128, 20)
output = m(input)
print(output.size())
```

## 2.2 matmul ç›¸å…³
**å›¾ç¤º** <br>
![figure10](images/op-figure10.jpg)

**pytorchä¸­æœ‰ä¸‰ä¸ªç›¸ä¼¼çš„çŸ©é˜µæ“ä½œ** <br>
- matmulæ˜¯é€šç”¨çš„çŸ©é˜µä¹˜æ³•å‡½æ•°ï¼Œé€‚ç”¨äºä¸åŒç»´åº¦çš„è¾“å…¥ã€‚
- bmmæ˜¯ç”¨äºæ‰¹é‡çŸ©é˜µä¹˜æ³•çš„å‡½æ•°ï¼Œè¦æ±‚è¾“å…¥ä¸º3ç»´å¼ é‡ã€‚
- mmæ˜¯ç”¨äºä¸¤ä¸ªäºŒç»´çŸ©é˜µä¹˜æ³•çš„å‡½æ•°ï¼Œè¦æ±‚è¾“å…¥ä¸º2ç»´å¼ é‡ã€‚

```python
import torch
tensor1 = torch.randn(10, 3, 4)
tensor2 = torch.randn(10, 4, 5)
torch.matmul(tensor1, tensor2).size()

mat1 = torch.randn(2, 3)
mat2 = torch.randn(3, 3)
torch.mm(mat1, mat2)

input = torch.randn(10, 3, 4)
mat2 = torch.randn(10, 4, 5)
res = torch.bmm(input, mat2)
res.size()
```

# 3 Normalization
**å‡ ç§Normalization å¯¹æ¯”** <br>
![figure4](images/op-figure4.jpg)

##  3.1 BatchNorm2d
**BNç¤ºæ„å›¾** <br>
![figure3](images/op-figure3.jpg)

**åŸç†:** <br>
- batchNormæ˜¯åœ¨batchä¸Šï¼Œå¯¹NHWåšå½’ä¸€åŒ–;å³æ˜¯å°†åŒä¸€ä¸ªbatchä¸­çš„æ‰€æœ‰æ ·æœ¬çš„åŒä¸€å±‚ç‰¹å¾å›¾æŠ½å‡ºæ¥ä¸€èµ·æ±‚meanå’Œvarianceã€‚<br>
- ä½†æ˜¯å½“batch sizeè¾ƒå°æ—¶(å°äº16æ—¶)ï¼Œæ•ˆæœä¼šå˜å·®ï¼Œè¿™æ—¶ä½¿ç”¨group normå¯èƒ½å¾—åˆ°çš„æ•ˆæœä¼šæ›´å¥½;
- åŠ å…¥ç¼©æ”¾å’Œå¹³ç§»å˜é‡ï¼Œæ”¹å˜æ•°æ®åˆ†å¸ƒçš„å‡å€¼å’Œæ–¹å·®ï¼›

**ä½œç”¨**ï¼š<br>
- é¦–å…ˆï¼Œåœ¨è¿›è¡Œè®­ç»ƒä¹‹å‰ï¼Œä¸€èˆ¬è¦å¯¹æ•°æ®åšå½’ä¸€åŒ–ï¼Œä½¿å…¶åˆ†å¸ƒä¸€è‡´,é˜²æ­¢å› è¾“å…¥æ•°æ®åˆ†å¸ƒå˜åŒ–å¯¹ç»“æœäº§ç”Ÿå½±å“ï¼›
- å…¶æ¬¡åœ¨ç½‘ç»œä¸­é—´ï¼Œä½¿ç”¨Batchnormï¼Œå°†æ•°æ®æ‹‰å›åˆ°æ­£æ€åˆ†å¸ƒï¼ŒåŠ å¿«æ”¶æ•›é€Ÿåº¦ï¼Œé˜²æ­¢æ¢¯åº¦æ¶ˆå¤±ï¼›
- åŠ å…¥ç¼©æ”¾å’Œå¹³ç§»å˜é‡çš„åŸå› æ˜¯ï¼šä¿è¯æ¯ä¸€æ¬¡æ•°æ®ç»è¿‡å½’ä¸€åŒ–åè¿˜ä¿ç•™åŸæœ‰å­¦ä¹ æ¥çš„ç‰¹å¾ï¼ŒåŒæ—¶åˆèƒ½å®Œæˆå½’ä¸€åŒ–æ“ä½œï¼ŒåŠ é€Ÿè®­ç»ƒã€‚ è¿™ä¸¤ä¸ªå‚æ•°æ˜¯ç”¨æ¥å­¦ä¹ çš„å‚æ•°ã€‚

**æ€è€ƒï¼šåœ¨è®­ç»ƒå’Œæ¨ç†æ—¶æœ‰ä½•ä¸åŒï¼Ÿï¼Ÿï¼Ÿ**

> pytorchçš„æ¨¡å‹æœ‰ä¸¤ç§æ¨¡å¼ï¼Œåœ¨moduleæ¨¡å—é‡Œé¢æœ‰ä¸ª`training`å±æ€§ï¼Œä¹Ÿæœ‰å¯¹åº”çš„APIï¼Œé‡Œé¢æ˜ç¡®æŒ‡å‡ºäº†è¿™ä¸ª
>
> åœ¨BatchNormé‡‡ç”¨è®­ç»ƒæ—¶è®¡ç®—çš„ç»“æœï¼ˆEå’ŒVarï¼‰ï¼Œåº”ç”¨åˆ°æµ‹è¯•æˆ–è€…æ¨ç†çš„æ—¶å€™
>
> åœ¨Dropoutåç»­ä¼šè¯´ï¼Œè®­ç»ƒä¼šdropæ‰ï¼Œä½†æ¨ç†ä¸ä¼šï¼Œä¼šæ”¹æˆï¼ˆ1-rateï¼‰

```python
def train(self: T, mode: bool = True) -> T:
    r"""Set the module in training mode.

    This has any effect only on certain modules. See documentations of
    particular modules for details of their behaviors in training/evaluation
    mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,
    etc.

    Args:
        mode (bool): whether to set training mode (``True``) or evaluation
                     mode (``False``). Default: ``True``.
```



- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d)

```python
# With Learnable Parameters
m = nn.BatchNorm2d(100)
# Without Learnable Parameters
m = nn.BatchNorm2d(100, affine=False)
input = torch.randn(20, 100, 35, 45)
output = m(input)
```

**æ‰‹åŠ¨å®ç°** <br>
```python
import numpy as np
def Batchnorm(x, gamma, beta, bn_param):
    # x_shape:[B, C, H, W]
    running_mean = bn_param['running_mean']
    running_var = bn_param['running_var']
    results = 0.
    eps = 1e-5

    x_mean = np.mean(x, axis=(0, 2, 3), keepdims=True)
    x_var = np.var(x, axis=(0, 2, 3), keepdims=True0)
    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)
    results = gamma * x_normalized + beta

    # å› ä¸ºåœ¨æµ‹è¯•æ—¶æ˜¯å•ä¸ªå›¾ç‰‡æµ‹è¯•ï¼Œè¿™é‡Œä¿ç•™è®­ç»ƒæ—¶çš„å‡å€¼å’Œæ–¹å·®ï¼Œç”¨åœ¨åé¢æµ‹è¯•æ—¶ç”¨
    running_mean = momentum * running_mean + (1 - momentum) * x_mean
    running_var = momentum * running_var + (1 - momentum) * x_var

    bn_param['running_mean'] = running_mean
    bn_param['running_var'] = running_var

    return results, bn_param
```

- [è®ºæ–‡é“¾æ¥](https://arxiv.org/pdf/1502.03167.pdf)

## 3.2 LayerNorm
**LN ç®€è¿°** <br>
- BNä¸é€‚ç”¨äºæ·±åº¦ä¸å›ºå®šçš„ç½‘ç»œï¼ˆå¦‚ RNN ä¸­çš„sequenceé•¿åº¦ï¼‰ï¼Œè€ŒLayerNormå¯¹æ·±åº¦ç½‘ç»œçš„æŸä¸€å±‚çš„æ‰€æœ‰ç¥ç»å…ƒè¿›è¡Œæ ‡å‡†åŒ–æ“ä½œï¼Œéå¸¸é€‚åˆç”¨äºåºåˆ—åŒ–è¾“å…¥ã€‚<br>
- LNä¸€èˆ¬åªç”¨äºRNNçš„åœºæ™¯ä¸‹ï¼Œåœ¨CNNä¸­LNè§„èŒƒåŒ–æ•ˆæœä¸å¦‚BN,GN,INã€‚
- LN å†NLPä¸­å¯¹æœ€åä¸€ä¸ªç»´åº¦æ±‚å‡å€¼å’Œæ–¹å·®ï¼Œéœ€æ³¨æ„çš„æ˜¯å¯è®­ç»ƒçš„weight å’Œ bias shape ç­‰äºæœ€åä¸€ä¸ªç»´åº¦ï¼Œå³ä¸€ä¸ªembedding çš„index å¯¹åº”ä¸€ä¸ªæƒé‡å’Œbias.

**BN å’Œ LN çš„åŒºåˆ«** <br>
1. LNä¸­åŒå±‚ç¥ç»å…ƒè¾“å…¥æ‹¥æœ‰ç›¸åŒçš„å‡å€¼å’Œæ–¹å·®ï¼Œä¸åŒçš„è¾“å…¥æ ·æœ¬æœ‰ä¸åŒçš„å‡å€¼å’Œæ–¹å·®ï¼›
2. BNä¸­åˆ™é’ˆå¯¹ä¸åŒç¥ç»å…ƒè¾“å…¥è®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼ŒåŒä¸€ä¸ªbatchä¸­çš„è¾“å…¥æ‹¥æœ‰ç›¸åŒçš„å‡å€¼å’Œæ–¹å·®ã€‚
3. æ‰€ä»¥ï¼ŒLNä¸ä¾èµ–äºbatchçš„å¤§å°å’Œè¾“å…¥sequenceçš„æ·±åº¦ï¼Œå› æ­¤å¯ä»¥ç”¨äºbatchsizeä¸º1å’ŒRNNä¸­å¯¹è¾¹é•¿çš„è¾“å…¥sequenceçš„normalizeæ“ä½œã€‚

**CV å’Œ NLP ä¸­ LNçš„åŒºåˆ«** <br>
![image](https://ask.qcloudimg.com/http-save/yehe-6930088/b6febb5b50b5392efe0d408629580481.png)

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm)
```python
import torch
import torch.nn as nn
batch, sentence_length, embedding_dim = 20, 5, 10
embedding = torch.randn(batch, sentence_length, embedding_dim)
layer_norm = nn.LayerNorm(embedding_dim)
# Activate module
output = layer_norm(embedding)
```

**æ‰‹åŠ¨å®ç°** <br>
```python
def ln(x, b, s):
    _eps = 1e-5
    output = (x - x.mean(1)[:,None]) / tensor.sqrt((x.var(1)[:,None] + _eps))
    output = s[None, :] * output + b[None,:]
    return output

# ç”¨äºå›¾åƒä¸Š
def Layernorm(x, gamma, beta):
    # x_shape:[B, C, H, W]
    results = 0.
    eps = 1e-5

    x_mean = np.mean(x, axis=(1, 2, 3), keepdims=True)
    x_var = np.var(x, axis=(1, 2, 3), keepdims=True0)
    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)
    results = gamma * x_normalized + beta
    return results
```

- [è®ºæ–‡é“¾æ¥](https://arxiv.org/pdf/1607.06450v1.pdf)

## 3.3 Instance Normalization
**ç®€è¿°** <br>
- BNæ³¨é‡å¯¹æ¯ä¸ªbatchè¿›è¡Œå½’ä¸€åŒ–ï¼Œä¿è¯æ•°æ®åˆ†å¸ƒä¸€è‡´ï¼Œå› ä¸ºåˆ¤åˆ«æ¨¡å‹ä¸­ç»“æœå–å†³äºæ•°æ®æ•´ä½“åˆ†å¸ƒã€‚
- ä½†æ˜¯å›¾åƒé£æ ¼åŒ–ä¸­ï¼Œç”Ÿæˆç»“æœä¸»è¦ä¾èµ–äºæŸä¸ªå›¾åƒå®ä¾‹ï¼Œæ‰€ä»¥å¯¹æ•´ä¸ªbatchå½’ä¸€åŒ–ä¸é€‚åˆå›¾åƒé£æ ¼åŒ–ä¸­ï¼Œå› è€Œå¯¹HWåšå½’ä¸€åŒ–ã€‚å¯ä»¥åŠ é€Ÿæ¨¡å‹æ”¶æ•›ï¼Œå¹¶ä¸”ä¿æŒæ¯ä¸ªå›¾åƒå®ä¾‹ä¹‹é—´çš„ç‹¬ç«‹ã€‚

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d)
```python
# Without Learnable Parameters
m = nn.InstanceNorm2d(100)
# With Learnable Parameters
m = nn.InstanceNorm2d(100, affine=True)
input = torch.randn(20, 100, 35, 45)
output = m(input)
```

**æ‰‹åŠ¨å®ç°** <br>
```python
def Instancenorm(x, gamma, beta):
    # x_shape:[B, C, H, W]
    results = 0.
    eps = 1e-5

    x_mean = np.mean(x, axis=(2, 3), keepdims=True)
    x_var = np.var(x, axis=(2, 3), keepdims=True0)
    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)
    results = gamma * x_normalized + beta
    return results
```
- [Instance è®ºæ–‡é“¾æ¥](https://arxiv.org/pdf/1607.08022.pdf)

## 3.4  Group Normalization
**åŸç†** <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ä¸»è¦æ˜¯é’ˆå¯¹Batch Normalizationå¯¹å°batchsizeæ•ˆæœå·®ï¼ŒGNå°†channelæ–¹å‘åˆ†groupï¼Œç„¶åæ¯ä¸ªgroupå†…åšå½’ä¸€åŒ–ï¼Œç®—(C//G)*H*Wçš„å‡å€¼ï¼Œè¿™æ ·ä¸batchsizeæ— å…³ï¼Œä¸å—å…¶çº¦æŸã€‚<br>

**GroupNormæ°¸è¿œä¸å†Batchç»´åº¦ä¸Šåšå¹³å‡** <br>

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html#torch.nn.GroupNorm)
```python
input = torch.randn(20, 6, 10, 10)
# Separate 6 channels into 3 groups
m = nn.GroupNorm(3, 6)
# Separate 6 channels into 6 groups (equivalent with InstanceNorm)
m = nn.GroupNorm(6, 6)
# Put all 6 channels into a single group (equivalent with LayerNorm)
m = nn.GroupNorm(1, 6)
# Activating the module
output = m(input)
```

**æ‰‹åŠ¨å®ç°** <br>
```python
def GroupNorm(x, gamma, beta, G=16):
    # x_shape:[B, C, H, W]
    results = 0.
    eps = 1e-5
    x = np.reshape(x, (x.shape[0], G, x.shape[1]/16, x.shape[2], x.shape[3]))

    x_mean = np.mean(x, axis=(2, 3, 4), keepdims=True)
    x_var = np.var(x, axis=(2, 3, 4), keepdims=True0)
    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)
    results = gamma * x_normalized + beta
    return results
```

## 3.5 Switch norm
- [è®ºæ–‡é“¾æ¥](https://arxiv.org/pdf/1806.10779.pdf)

SNæ˜¯ä¸€ç§è¦†ç›–ç‰¹å¾å›¾å¼ é‡å„ä¸ªç»´åº¦æ¥è®¡ç®—ç»Ÿè®¡ä¿¡æ¯çš„å½’ä¸€åŒ–æ–¹æ³•ï¼Œä¸ä¾èµ–minibatch sizeçš„åŒæ—¶å¯¹å„ä¸ªç»´åº¦ç»Ÿè®¡æœ‰å¾ˆå¥½çš„é²æ£’æ€§. <br>

![figure15](images/op-figure15.jpg)

![figure16](images/op-figure16.jpg)

## 3.6 RMS Norm
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layer normalization é‡è¦çš„ä¸¤ä¸ªéƒ¨åˆ†æ˜¯å¹³ç§»ä¸å˜æ€§å’Œç¼©æ”¾ä¸å˜æ€§ã€‚Root Mean Square Layer Normalization è®¤ä¸º layer normalization å–å¾—æˆåŠŸé‡è¦çš„æ˜¯ç¼©æ”¾ä¸å˜æ€§ï¼Œè€Œä¸æ˜¯å¹³ç§»ä¸å˜æ€§ã€‚å› æ­¤ï¼Œå»é™¤äº†è®¡ç®—è¿‡ç¨‹ä¸­çš„å¹³ç§»ï¼Œåªä¿ç•™äº†ç¼©æ”¾ï¼Œè¿›è¡Œäº†ç®€åŒ–ï¼Œæå‡ºäº†RMS Norm (Root Mean Square Layer Normalization)ï¼Œå³å‡æ–¹æ ¹ normã€‚<br>

- [è®ºæ–‡é“¾æ¥](https://arxiv.org/pdf/1910.07467.pdf)

## 3.7 DeepNormè¡¥å……

DeepNorm æ˜¯å¾®è½¯åœ¨ 2022 å¹´æå‡ºçš„æ”¹è¿›æ–¹æ³•ï¼ˆè®ºæ–‡ *"[DeepNet: Scaling Transformers to 1,000 Layers](https://arxiv.org/abs/2203.00555)"*ï¼‰ï¼Œ**åŸºäº Post-Norm ä½†å¤§å¹…æå‡äº†æ·±å±‚è®­ç»ƒçš„ç¨³å®šæ€§**ï¼Œå¯æ”¯æŒè¶…æ·±å±‚ï¼ˆå¦‚ 1000 å±‚ï¼‰Transformer çš„è®­ç»ƒã€‚

![image-20250409164334392](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250409164334392.png)

![image-20250409162034019](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250409162034019.png)

**åŸå§‹æ®‹å·®ç»“æ„:**
$$
x_{l+1} = LayerNorm(x_l + F(x_l))
$$
**DeepNorm:**
$$
x_{l+1} = \text{LN}(\alpha \cdot x_l + G_l(x_l, \theta_l))
$$
![image-20250409164837814](https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250409164837814.png)

**æ€è€ƒï¼š**DeepNormä¸­çš„$\beta$æ˜¯å“ªé‡Œçš„å‚æ•°ï¼Ÿ

## 3.8 DyTè¡¥å……

> 2025ï¼šTransformers without normlization

å½’ä¸€åŒ–å±‚åœ¨ç°ä»£ç¥ç»ç½‘ç»œä¸­æ— å¤„ä¸åœ¨ï¼Œé•¿æœŸä»¥æ¥è¢«è®¤ä¸ºæ˜¯å¿…ä¸å¯å°‘çš„ã€‚ æœ¬å·¥ä½œè¯æ˜ï¼Œä½¿ç”¨ä¸€ç§éå¸¸ç®€å•çš„æŠ€æœ¯ï¼Œæ— å½’ä¸€åŒ–çš„Transformerå¯ä»¥è¾¾åˆ°ç›¸åŒæˆ–æ›´å¥½çš„æ€§èƒ½ã€‚ **æˆ‘ä»¬å¼•å…¥äº†åŠ¨æ€åŒæ›²æ­£åˆ‡å‡½æ•°(DyT)ï¼Œä¸€ç§é€å…ƒç´ è¿ç®—$DyTâ¢(ğ’™)=tanhâ¡(Î±â¢ğ’™)$ï¼Œä½œä¸ºTransformerä¸­å½’ä¸€åŒ–å±‚çš„ç›´æ¥æ›¿ä»£ã€‚** DyTçš„çµæ„Ÿæ¥è‡ªäºè¿™æ ·çš„è§‚å¯Ÿï¼šTransformerä¸­çš„å±‚å½’ä¸€åŒ–é€šå¸¸ä¼šäº§ç”Ÿç±»ä¼¼tanhå‡½æ•°çš„Så½¢è¾“å…¥-è¾“å‡ºæ˜ å°„ã€‚ é€šè¿‡ç»“åˆDyTï¼Œæ— å½’ä¸€åŒ–çš„Transformerå¯ä»¥åŒ¹é…æˆ–è¶…è¶Šå…¶å½’ä¸€åŒ–å¯¹åº”ç‰©çš„æ€§èƒ½ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸‹æ— éœ€è¶…å‚æ•°è°ƒæ•´ã€‚ æˆ‘ä»¬åœ¨ä¸åŒçš„ç¯å¢ƒä¸­éªŒè¯äº†å…·æœ‰DyTçš„Transformerçš„æœ‰æ•ˆæ€§ï¼ŒèŒƒå›´ä»è¯†åˆ«åˆ°ç”Ÿæˆï¼Œä»ç›‘ç£å­¦ä¹ åˆ°è‡ªç›‘ç£å­¦ä¹ ï¼Œä»¥åŠä»è®¡ç®—æœºè§†è§‰åˆ°è¯­è¨€æ¨¡å‹ã€‚ è¿™äº›å‘ç°æŒ‘æˆ˜äº†å½’ä¸€åŒ–å±‚åœ¨ç°ä»£ç¥ç»ç½‘ç»œä¸­ä¸å¯æˆ–ç¼ºçš„ä¼ ç»Ÿè®¤è¯†ï¼Œå¹¶ä¸ºå…¶åœ¨æ·±åº¦ç½‘ç»œä¸­çš„ä½œç”¨æä¾›äº†æ–°çš„è§è§£ã€‚

[è®ºæ–‡è¿æ¥](https://yiyibooks.cn/arxiv/2503.10622v1/index.html)

ä¼ªä»£ç ï¼š

```python
# input x has the shape of [B, T, C]
# B: batch size, T: tokens, C:dimension

class DyT(Module):
    def __init__(self, C, init_âº):
        super().__init__()
        self.âº = Parameter(ones(1) * init_Î±)
        self.Î³ = Parameter(ones(C))
        self.Î² = Parameter(zeros(C))
        
    def forward(self, x):
        x = tanh(self.alpha * x)
        return self.Î³ * x + self.Î² 
```



> Noteï¼šæ•´ä½“å›é¡¾ä¸€ä¸‹ç®—å­éƒ¨åˆ†ï¼Œå¼•å…¥åé¢çš„ç®—å­ï¼Œä¸ç„¶å¤§è„‘è¿˜åœç•™åœ¨norméƒ¨åˆ†



# 4 Pooling
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pooling(æ± åŒ–)æ˜¯CNN ä¸­å¸¸ç”¨çš„æ“ä½œï¼Œé€šè¿‡åœ¨ç‰¹å®šåŒºåŸŸå†…å¯¹ç‰¹å¾è¿›è¡Œ(reduce)æ¥å®ç°çš„ã€‚<br>

**ä½œç”¨** <br>
- å¢å¤§ç½‘ç»œæ„Ÿå—é‡
- å‡å°ç‰¹å¾å›¾å°ºå¯¸ï¼Œä½†ä¿ç•™é‡è¦çš„ç‰¹å¾ä¿¡æ¯
- æŠ‘åˆ¶å™ªå£°ï¼Œé™ä½ä¿¡æ¯å†—ä½™
- é™ä½æ¨¡å‹è®¡ç®—é‡ï¼Œé™ä½ç½‘ç»œä¼˜åŒ–éš¾åº¦ï¼Œé˜²æ­¢ç½‘ç»œè¿‡æ‹Ÿåˆ
- ä½¿æ¨¡å‹å¯¹è¾“å…¥å›¾åƒä¸­çš„ç‰¹å¾ä½ç½®å˜åŒ–æ›´åŠ é²æ£’

## 4.1 Max Pooling
**åŸç†** <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;æœ€å¤§æ± åŒ–åœ¨æ¯ä¸ªæ± åŒ–çª—å£ä¸­é€‰æ‹©æœ€å¤§çš„ç‰¹å¾å€¼ä½œä¸ºè¾“å‡ºï¼Œæå–ç‰¹å¾å›¾ä¸­å“åº”æœ€å¼ºçƒˆçš„éƒ¨åˆ†è¿›å…¥ä¸‹ä¸€å±‚; <br>
![figure7](images/op-figure7.jpg)

![figure7](images/op-figure8.jpg)

**ä½œç”¨** <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;è¿™ç§æ–¹å¼æ‘’å¼ƒäº†ç½‘ç»œä¸­å¤§é‡çš„å†—ä½™ä¿¡æ¯ï¼Œä½¿å¾—ç½‘ç»œæ›´å®¹æ˜“è¢«ä¼˜åŒ–ã€‚åŒæ—¶è¿™ç§æ“ä½œæ–¹å¼ä¹Ÿå¸¸å¸¸ä¸¢å¤±äº†ä¸€äº›ç‰¹å¾å›¾ä¸­çš„ç»†èŠ‚ä¿¡æ¯ï¼Œæ‰€ä»¥æœ€å¤§æ± åŒ–æ›´å¤šä¿ç•™äº›å›¾åƒçš„çº¹ç†ä¿¡æ¯ã€‚<br>

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d)
```python
import torch.nn as nn
# pool of square window of size=3, stride=2
m = nn.MaxPool2d(3, stride=2)
# pool of non-square window
m = nn.MaxPool2d((3, 2), stride=(2, 1))
input = torch.randn(20, 16, 50, 32)
output = m(input)
```

## 4.2 AveragePooling
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;å¹³å‡æ± åŒ–åœ¨æ¯ä¸ªæ± åŒ–çª—å£ä¸­é€‰æ‹©ç‰¹å¾å€¼çš„å¹³å‡å€¼ä½œä¸ºè¾“å‡ºï¼Œè¿™æœ‰åŠ©äºä¿ç•™æ•´ä½“ç‰¹å¾ä¿¡æ¯ï¼Œå¯ä»¥æ›´å¤šçš„ä¿ç•™å›¾åƒçš„èƒŒæ™¯ä¿¡æ¯ï¼Œä½†å¯èƒ½ä¼šä¸¢å¤±ä¸€äº›ç»†èŠ‚ã€‚<br>

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html#torch.nn.AvgPool2d)
```python
import torch.nn as nn
# pool of square window of size=3, stride=2
m = nn.AvgPool2d(3, stride=2)
# pool of non-square window
m = nn.AvgPool2d((3, 2), stride=(2, 1))
input = torch.randn(20, 16, 50, 32)
output = m(input)
```

## 4.3 Global Average Pooling
![figure6](images/op-figure6.jpg)

**èƒŒæ™¯** <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;åœ¨å·ç§¯ç¥ç»ç½‘ç»œè®­ç»ƒåˆæœŸï¼Œå·ç§¯å±‚é€šè¿‡æ± åŒ–å±‚åä¸€èˆ¬è¦æ¥å¤šä¸ªå…¨è¿æ¥å±‚è¿›è¡Œé™ç»´ï¼Œæœ€åå†Softmaxåˆ†ç±»ï¼Œè¿™ç§åšæ³•ä½¿å¾—å…¨è¿æ¥å±‚å‚æ•°å¾ˆå¤šï¼Œé™ä½äº†ç½‘ç»œè®­ç»ƒé€Ÿåº¦ï¼Œä¸”å®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆçš„æƒ…å†µã€‚åœ¨è¿™ç§èƒŒæ™¯ä¸‹ï¼ŒM Linç­‰äººæå‡ºä½¿ç”¨å…¨å±€å¹³å‡æ± åŒ–Global Average Pooling[1]æ¥å–ä»£æœ€åçš„å…¨è¿æ¥å±‚ã€‚ç”¨å¾ˆå°çš„è®¡ç®—ä»£ä»·å®ç°äº†é™ç»´ï¼Œæ›´é‡è¦çš„æ˜¯GAPæå¤§å‡å°‘äº†ç½‘ç»œå‚æ•°(CNNç½‘ç»œä¸­å…¨è¿æ¥å±‚å æ®äº†å¾ˆå¤§çš„å‚æ•°)ã€‚<br>

**å®ç°åŸç†** <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;å…¨å±€å¹³å‡æ± åŒ–æ˜¯åœ¨æ•´ä¸ªç‰¹å¾å›¾ä¸Šè®¡ç®—ç‰¹å¾å€¼çš„å¹³å‡å€¼ï¼Œç„¶åå°†ç»“æœä½œä¸ºä¸€ä¸ªç‰¹å¾å‘é‡è¾“å‡ºåˆ°ä¸‹ä¸€å±‚ï¼Œè¿™ç§æ± åŒ–æ–¹æ³•é€šå¸¸åœ¨ç½‘ç»œæœ€åã€‚<br>

**ä½œç”¨** <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ä½œä¸ºå…¨è¿æ¥å±‚çš„æ›¿ä»£æ“ä½œï¼ŒGAPå¯¹æ•´ä¸ªç½‘ç»œåœ¨ç»“æ„ä¸Šåšæ­£åˆ™åŒ–é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œç›´æ¥å‰”é™¤äº†å…¨è¿æ¥å±‚ä¸­é»‘ç®±çš„ç‰¹å¾ï¼Œç›´æ¥èµ‹äºˆäº†æ¯ä¸ªchannelå®é™…çš„ç±»åˆ«æ„ä¹‰ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œä½¿ç”¨GAPä»£æ›¿å…¨è¿æ¥å±‚ï¼Œå¯ä»¥å®ç°ä»»æ„å›¾åƒå¤§å°çš„è¾“å…¥ï¼Œè€ŒGAPå¯¹æ•´ä¸ªç‰¹å¾å›¾æ±‚å¹³å‡å€¼ï¼Œä¹Ÿå¯ä»¥ç”¨æ¥æå–å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå…¨å±€ä¿¡æ¯ä½œä¸ºæŒ‡å¯¼è¿›ä¸€æ­¥å¢å¼ºç½‘ç»œæ€§èƒ½ã€‚<br>

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html#torch.nn.AdaptiveAvgPool2d)
```python
import torch
import torch.nn as nn
# target output size of 5x7
m = nn.AdaptiveAvgPool2d((5, 7))
input = torch.randn(1, 64, 8, 9)
output = m(input)
# target output size of 7x7 (square)
m = nn.AdaptiveAvgPool2d(7)
input = torch.randn(1, 64, 10, 9)
output = m(input)
# target output size of 10x7
m = nn.AdaptiveAvgPool2d((None, 7))
input = torch.randn(1, 64, 10, 9)
output = m(input)
```
- [GlobalAvgPool è®ºæ–‡é“¾æ¥](https://arxiv.org/pdf/1312.4400.pdf%20http://arxiv.org/abs/1312.4400.pdf)

# 5 activation functions

- [å‚è€ƒä¸‹ä¸€è¯¾æ—¶](../8-activation_functions/activations.md)

# 6 reshapeã€ viewã€ permuteã€transpose
## 6.1 reshape 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;è¿”å›ä¸€ä¸ªå…·æœ‰ä¸è¾“å…¥ç›¸åŒçš„æ•°æ®å’Œå…ƒç´ æ•°é‡ï¼Œä½†å…·æœ‰æŒ‡å®šå½¢çŠ¶çš„å¼ é‡ã€‚å¦‚æœå¯èƒ½çš„è¯ï¼Œè¿”å›çš„å¼ é‡å°†æ˜¯è¾“å…¥çš„è§†å›¾ã€‚å¦åˆ™ï¼Œå®ƒå°†æ˜¯ä¸€ä¸ªå‰¯æœ¬ã€‚è¿ç»­çš„è¾“å…¥å’Œå…·æœ‰å…¼å®¹æ­¥å¹…çš„è¾“å…¥å¯ä»¥è¿›è¡Œé‡å¡‘è€Œæ— éœ€å¤åˆ¶ï¼Œä½†æ‚¨ä¸åº”ä¾èµ–äºå¤åˆ¶ä¸è§†å›¾è¡Œä¸ºã€‚<br>

![figure11](images/op-figure11.jpg)

[pytorch reshapes å®ç°](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch-reshape)
```python
a = torch.arange(4.)
torch.reshape(a, (2, 2))
b = torch.tensor([[0, 1], [2, 3]])
torch.reshape(b, (-1,))
```

## 6.2 view
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;è¿”å›åŸå§‹æ•°æ®çš„ä¸åŒshapeã€‚<br>

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html#torch.Tensor.view)
```python
x = torch.randn(4, 4)
x.size()
y = x.view(16)
y.size()
z = x.view(-1, 8)  # the size -1 is inferred from other dimensions
z.size()

a = torch.randn(1, 2, 3, 4)
a.size()
b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension
b.size()
c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory
c.size()
torch.equal(b, c)
```

## 6.3 transpose
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;äº¤æ¢Tensorçš„ä¸¤ä¸ªè½´å¹¶è¿”å›ã€‚<br>
![figure12](images/op-figure12.jpg)

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.transpose.html#torch-transpose)
```python
x = torch.randn(2, 3)
x
torch.transpose(x, 0, 1)
```

## 6.4 permute
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tensor å¤šè½´äº¤æ¢ã€‚<br>
- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.permute.html#torch-permute)
```python
x = torch.randn(2, 3, 5)
x.size()
torch.permute(x, (2, 0, 1)).size()
```

# 7 sequenze å’Œ unequenze
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;å‹ç¼©ç»´åº¦ä¸è§£å‹ç»´åº¦ã€‚<br>

**å›¾åƒ** <br>
![figure13](images/op-figure13.jpg)

# 8 concatã€stackã€expand å’Œ flatten
## 8.1 concat
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;åœ¨ç»™å®šçš„ç»´åº¦ä¸Šæ‹¼æ¥ç»™å®šçš„åºåˆ—å¼ é‡ã€‚æ‰€æœ‰å¼ é‡å¿…é¡»å…·æœ‰ç›¸åŒçš„å½¢çŠ¶ï¼ˆé™¤äº†æ‹¼æ¥ç»´åº¦ï¼‰ï¼Œæˆ–è€…ä¸ºç©ºã€‚æ˜¯split çš„é€†è¿ç®—ï¼Œæ˜¯torch.catçš„åˆ«åã€‚<br>

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat)
```python
x = torch.randn(2, 3)
torch.cat((x, x, x), 0)
torch.cat((x, x, x), 1)
```
## 8.2 stack
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;åœ¨æ–°è½´ä¸Šæ‹¼æ¥Tensorã€‚
```python
a = torch.randn(2,3)
b = torch.randn(2,3)
c= torch.stack([a,b], dim=1)
```

## 8.3 expand
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;è¿”å›ä¸€ä¸ªselfå¼ é‡çš„æ–°è§†å›¾ï¼Œå…¶ä¸­çš„å•ä¾‹ç»´åº¦è¢«æ‰©å±•åˆ°æ›´å¤§çš„å¤§å°ã€‚<br>

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html)
```python
x = torch.tensor([[1], [2], [3]])
x.size()
x.expand(3, 4)
x.expand(-1, 4)   # -1 means not changing the size of that dimension
```
**æ€è€ƒï¼šexpand åçš„å½¢çŠ¶å¯ä»¥éšä¾¿å†™å—ï¼Ÿéœ€è¦æ»¡è¶³ä»€ä¹ˆè§„åˆ™ ï¼Ÿï¼Ÿï¼Ÿ** <br>

## 8.4 flatten
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;é€šè¿‡å°†è¾“å…¥å¼ é‡é‡å¡‘ä¸ºä¸€ç»´å¼ é‡æ¥å¯¹å…¶è¿›è¡Œæ‰å¹³åŒ–ã€‚å¦‚æœä¼ é€’äº†start_dimæˆ–end_dimï¼Œåˆ™åªæœ‰ä»¥start_dimå¼€å¤´ä¸”ä»¥end_dimç»“å°¾çš„ç»´åº¦è¢«æ‰å¹³åŒ–ã€‚è¾“å…¥ä¸­å…ƒç´ çš„é¡ºåºä¿æŒä¸å˜ã€‚<br>

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.flatten.html#torch-flatten)
```python
t = torch.tensor([[[1, 2],
                   [3, 4]],
                  [[5, 6],
                   [7, 8]]])
torch.flatten(t)
torch.flatten(t, start_dim=1)
```

# 9 pointwise
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tensor ä¸­é€å…ƒç´ è¿›è¡Œçš„æ“ä½œï¼Œä¹Ÿå«element wise æ“ä½œï¼Œå¤§éƒ¨åˆ†çš„activation ç®—å­ä»¥åŠ addã€subã€mulã€divã€sqrt ç­‰éƒ½å±äºpointwise ç±»åˆ«ã€‚<br>

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.sqrt.html#torch.sqrt)
```python
a = torch.randn(4)
torch.sqrt(a)
```
**æ€è€ƒï¼šä¸åŒç»´åº¦çš„ä¸¤ä¸ªTensor å¯ä»¥è¿›è¡Œpointwise æ“ä½œå—ï¼Ÿ èƒ½çš„è¯è§„åˆ™æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿï¼Ÿï¼Ÿ** <br>

# 10 split å’Œ slice
## 10.1 split
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;å°†å¼ é‡åˆ†å‰²æˆå¤šä¸ªå—ã€‚æ¯ä¸ªå—éƒ½æ˜¯åŸå§‹å¼ é‡çš„è§†å›¾ã€‚<br>
- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.split.html#torch.split)

```python
a = torch.arange(10).reshape(5, 2)
torch.split(a, 2)
torch.split(a, [1, 4])
```
**æ€è€ƒï¼šæ˜¯æ²¿ç€é‚£ä¸ªè½´è¿›è¡Œsplit å‘¢ï¼Ÿï¼Ÿ** <br>

## 10.2 slice
**ç›´æ¥ç”¨ç´¢å¼•æ¥å®ç°** <br>
```python
import torch
# åˆ›å»ºä¸€ä¸ªç¤ºä¾‹å¼ é‡
tensor = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
# å¯¹å¼ é‡è¿›è¡Œåˆ‡ç‰‡
slice_tensor = tensor[2:7]  # ä»ç´¢å¼•2åˆ°ç´¢å¼•6ï¼ˆä¸åŒ…å«7ï¼‰
print(slice_tensor)  # è¾“å‡º: tensor([3, 4, 5, 6, 7])
# ä½¿ç”¨æ­¥é•¿å¯¹å¼ é‡è¿›è¡Œåˆ‡ç‰‡
step_slice_tensor = tensor[1:9:2]  # ä»ç´¢å¼•1åˆ°ç´¢å¼•8ï¼ˆä¸åŒ…å«9ï¼‰ï¼Œæ­¥é•¿ä¸º2
print(step_slice_tensor)  # è¾“å‡º: tensor([2, 4, 6, 8])
# çœç•¥èµ·å§‹ç´¢å¼•å’Œç»“æŸç´¢å¼•æ¥é€‰æ‹©æ•´ä¸ªå¼ é‡
full_tensor = tensor[:]
print(full_tensor)  # è¾“å‡º: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
```

# 11 reduce è§„çº¦ç±»ç®—å­
**mean** <br>
```python
a = torch.randn(4, 4)
torch.mean(a, 1)
torch.mean(a, 1, True)
```
**var** <br>
```python
a = torch.tensor(
    [[ 0.2035,  1.2959,  1.8101, -0.4644],
     [ 1.5027, -0.3270,  0.5905,  0.6538],
     [-1.5745,  1.3330, -0.5596, -0.6548],
     [ 0.1264, -0.5080,  1.6420,  0.1992]])
torch.var(a, dim=1, keepdim=True)
```
**sum** <br>
```python
a = torch.randn(4, 4)
torch.sum(a, 1)
b = torch.arange(4 * 5 * 6).view(4, 5, 6)
torch.sum(b, (2, 1))
```

**max** <br>
```python
a = torch.randn(4, 4)
torch.max(a, 1)
```

**min** <br>
```python
a = torch.randn(4, 4)
torch.min(a, 1)
```

# 12 embedding
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;è¿™ä¸ªæ¨¡å—ç»å¸¸è¢«ç”¨æ¥å­˜å‚¨å•è¯åµŒå…¥ï¼Œå¹¶ä½¿ç”¨ç´¢å¼•æ¥æ£€ç´¢å®ƒä»¬ã€‚è¯¥æ¨¡å—çš„è¾“å…¥æ˜¯ä¸€ä¸ªç´¢å¼•åˆ—è¡¨ï¼Œè¾“å‡ºæ˜¯ç›¸åº”çš„å•è¯åµŒå…¥ã€‚<br>

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding)
```python
# an Embedding module containing 10 tensors of size 3
embedding = nn.Embedding(10, 3)
# a batch of 2 samples of 4 indices each
input = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])
embedding(input)

# example with padding_idx
embedding = nn.Embedding(10, 3, padding_idx=0)
input = torch.LongTensor([[0, 2, 0, 5]])
embedding(input)

# example of changing `pad` vector
padding_idx = 0
embedding = nn.Embedding(3, 3, padding_idx=padding_idx)
embedding.weight
with torch.no_grad():
    embedding.weight[padding_idx] = torch.ones(3)
embedding.weight

# FloatTensor containing pretrained weights
weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])
embedding = nn.Embedding.from_pretrained(weight)
# Get embeddings for index 1
input = torch.LongTensor([1])
embedding(input)
```

# 13 dropout
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨ä»ä¼¯åŠªåˆ©åˆ†å¸ƒä¸­é‡‡æ ·çš„æ ·æœ¬ï¼Œä»¥æ¦‚ç‡péšæœºå°†è¾“å…¥å¼ é‡çš„æŸäº›å…ƒç´ ç½®é›¶ã€‚æ¯ä¸ªé€šé“åœ¨æ¯æ¬¡å‰å‘è°ƒç”¨æ—¶éƒ½ä¼šç‹¬ç«‹åœ°è¢«ç½®é›¶ã€‚<br>

**åŸç†å›¾** <br>
![figure14](images/op-figure14.jpg)

- [pytorch å®ç°](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout)
```python
m = nn.Dropout(p=0.2)
input = torch.randn(20, 16)
output = m(input)
```

**æ€è€ƒï¼šè®­ç»ƒå’Œæ¨ç†æ—¶è¿™ä¸ªç®—å­è¡¨ç°æœ‰ä½•ä¸åŒ ï¼Ÿï¼Ÿï¼Ÿ*** <br>

- [è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/1207.0580)

# 14 é™„å½•
- [onnx ç®—å­åˆ—è¡¨](https://github.com/onnx/onnx/blob/main/docs/Operators.md) <br>
- [pytorch ç®—å­åˆ—è¡¨](https://pytorch.org/docs/stable/nn.html) <br>

# 15 å‚è€ƒé“¾æ¥
- [æ¿€æ´»å‡½æ•°æ±‡æ€»](http://spytensor.com/index.php/archives/23/?xqrspi=xnemo1) <br>
- [æ¿€æ´»å‡½æ•°ç»¼è¿°](https://www.xhuqk.com/xhdxxbzkb/article/doi/10.12198/j.issn.1673-159X.3761) <br>
- [Activation å¯è§†åŒ–](https://dashee87.github.io/deep%20learning/visualising-activation-functions-in-neural-networks/) <br>
