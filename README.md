# deep_learning_theory
Summary of deep learning theory



## Lessons Additions and Adjustments

### 内容补充：

| 序号 | 补充内容                                                     | 状态 |
| :--: | :----------------------------------------------------------- | :--: |
| 001  | update：softmax 激活函数的导数引出一下（雅可比矩阵）         |  0   |
| 002  | add：Norm 讲解的时候，未加入最新的 DyT（[Transformers without normalization](https://yiyibooks.cn/arxiv/2503.10622v1/index.html)） |  0   |
| 004  | add：DeepNorm 补充                                           |  0   |
| 005  | add：PyTorch 等框架模型结构中的参数类型和数据整理（我的笔记） |  0   |
| 006  | 思考：工程如何实现训练和推理不同的模块或者算子（那个 training 参数和具体的算子结构） |  0   |
| 007  |                                                              |  0   |



### 调整建议:

| 序号 | 调整建议                                                     | 状态 |
| :--: | :----------------------------------------------------------- | :--: |
| 001  | updata：torch 的 Tensor 中，数据有 metadata 和 storage 之分（之前讲成 rawdata，但官网未使用这种叫法） [torch.Srorage](https://pytorch.org/docs/stable/storage.html) |  0   |
| 002  | 优化：前后知识交叉部分可以切回到原理快速回顾一下（比如：训练模式与Norm和Dropout、torch的数据结构与一些基础算子等） |  0   |
|      |                                                              |      |
|      |                                                              |      |
|      |                                                              |      |

